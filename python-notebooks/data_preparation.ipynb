{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and merge it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atm = pd.read_csv(\"GDAIR_train_data.csv\", sep=\";\") # Read atmospheric data\n",
    "df_atm[\"Date\"] = pd.to_datetime(df_atm[['Year', 'Month', 'Day']])\n",
    "df_pm = pd.read_csv(\"data_pm.csv\") # read PM10 data\n",
    "df_pm[\"Date\"] = pd.to_datetime(df_pm[\"Date\"])\n",
    "df = df_atm.merge(df_pm, how=\"left\", on=\"Date\") # Merge atmospheric data with PM10 data\n",
    "df = df[(df[\"Date\"] >= \"2015-01-01\") & (df[\"Date\"] <= \"2024-06-30\")] # Filter data for the years 2015 to 2024\n",
    "df.drop([\"Year\", \"Day\"], inplace=True, axis=1) # Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum()) # Check for missing values\n",
    "imputer = KNNImputer(n_neighbors=10) # Initialize KNN imputer with 10 neighbors\n",
    "df_to_impute = df.iloc[:, 2:]\n",
    "df_imputed_part = pd.DataFrame(imputer.fit_transform(df_to_impute), columns=df_to_impute.columns)\n",
    "df_imputed = pd.concat([df.iloc[:, :2], df_imputed_part], axis=1) # Concatenate imputed data with original date columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_columns = df.select_dtypes(include=[\"number\"]).columns # Select numeric columns\n",
    "for col in value_columns: # Plot each numeric column\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(df[\"Date\"], df[col], label=col)\n",
    "    plt.title(f\"{col} over time\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding additional features\n",
    "pl_holidays = holidays.Poland(years=range(2015, 2025)) # Create a list of Polish holidays from 2015 to 2024\n",
    "df_imputed['IsWeekend'] = df_imputed['Date'].dt.weekday < 5  # Weekday is 0-4 (Monday to Friday), weekend is 5-6 (Saturday and Sunday)\n",
    "df_imputed['IsHoliday'] = df_imputed['Date'].isin(pl_holidays) # Check if the date is a holiday\n",
    "# Convert boolean columns to integers (0 and 1)\n",
    "df_imputed['IsWeekend'] = df_imputed['IsWeekend'].astype(int)\n",
    "df_imputed['IsHoliday'] = df_imputed['IsHoliday'].astype(int)\n",
    "\n",
    "def get_season(date): # Function to determine the season based on the date\n",
    "    if (date.month == 12 and date.day >= 21) or (date.month <= 2) or (date.month == 3 and date.day <= 20):\n",
    "        return 4  # Winter\n",
    "    elif (date.month == 3 and date.day >= 21) or (date.month <= 6 and date.day <= 20):\n",
    "        return 1  # Spring\n",
    "    elif (date.month == 6 and date.day >= 21) or (date.month <= 9 and date.day <= 20):\n",
    "        return 2  # Summer\n",
    "    else:\n",
    "        return 3  # Autumn\n",
    "\n",
    "df_imputed['Season'] = df_imputed['Date'].apply(get_season) # Apply the get_season function to each date in the DataFrame\n",
    "df_imputed['Risk'] = np.where(df_imputed['PM10'] > 50, 1, 0) # Create a risk column based on PM10 levels\n",
    "df_imputed['FutureRisk'] = df_imputed['Risk'].shift(-1).fillna(0).astype(int) # Shift the risk column to create a future risk column\n",
    "df_imputed.drop([\"Risk\"], inplace=True, axis=1) # Drop the original risk column\n",
    "df_imputed.groupby(\"FutureRisk\").count() # Count the number of occurrences of each future risk value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.to_excel('data.xlsx') # Save the DataFrame to an Excel file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
