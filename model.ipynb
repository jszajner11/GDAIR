{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0326e2d6",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f015d9",
   "metadata": {},
   "source": [
    "## Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd67451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "df_no_risk = pd.read_excel(\"modified_data.xlsx\", sheet_name=\"Datanorisk\")\n",
    "df_risk = pd.read_excel(\"modified_data.xlsx\", sheet_name=\"Datarisk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0d385",
   "metadata": {},
   "source": [
    "## Creating sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec6f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "def create_sequence_and_label(df, label): # Create sequences of 3 rows and assign a label\n",
    "    sequences=[] # List to store sequences\n",
    "    i = 0 # Initialize index\n",
    "    while i < len(df): # Loop through the dataframe\n",
    "        seq = df.iloc[i:i + 3].values.flatten() # Get 3 rows and flatten them into a single row\n",
    "        sequences.append(seq) \n",
    "        i = i+3 # Move to the next sequence\n",
    "    return pd.DataFrame(sequences).assign(label=label) # Assign the label\n",
    "\n",
    "# Create sequences for both classes\n",
    "df1 = create_sequence_and_label(df_no_risk, label=0)\n",
    "df2 = create_sequence_and_label(df_risk, label=1)\n",
    "\n",
    "original_cols = df_no_risk.columns.tolist() # Get the original column names\n",
    "\n",
    "# Rename columns for 3-day sequences\n",
    "column_names = (\n",
    "    original_cols +\n",
    "    [f\"{col}_2\" for col in original_cols] +\n",
    "    [f\"{col}_3\" for col in original_cols] +\n",
    "    [\"label\"]\n",
    ")\n",
    "df1.columns = column_names\n",
    "df2.columns = column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff26f19",
   "metadata": {},
   "source": [
    "## Oversampling and creating train-test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the dataset\n",
    "df2_oversampling = resample(df2, # Resampling label 1\n",
    "                            replace=True, \n",
    "                            n_samples=1000, # Number of samples to generate\n",
    "                            random_state=42)  # Random state for reproducibility\n",
    "\n",
    "# Concatenate both datasets\n",
    "df_balanced = pd.concat([df1, df2_oversampling])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Creating X and y variables for the model\n",
    "X = df_balanced.drop('label', axis=1)\n",
    "y = df_balanced['label']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3, # 30% for testing\n",
    "                                                    random_state=42\n",
    "                                                    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27501117",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, # Number of trees in the forest\n",
    "                                  random_state=42) # Random state for reproducibility\n",
    "\n",
    "# Fitting the model to the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "print(\"Feature Importances:\", importances)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
